# EYES

The proposed idea for senior project is to develop an accessible app for the visually impaired to help them navigate and virtually “see” the world around them. The app would aim have the following features: Text recognition, Object recognition, Scene recognition and Color Recognition.

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.

### Prerequisites

- Android Studio 3.5
- Java
- Gradle
- Android Phone with API Level 21
- Google Firebase ML Kit
- Microsoft Computer Vision
- Google Text-to-Speech
- Google Speech Recognizer
- Camera Kit

```
Give examples
```

### Installing

A step by step series of examples that tell you how to get a development env running

Say what the step will be

```
Give the example
```

And repeat

```
until finished
```

End with an example of getting some data out of the system or using it for a little demo

## Running the tests

Explain how to run the automated tests for this system

### Break down into end to end tests

Explain what these tests test and why

```
Give an example
```

### And coding style tests

Explain what these tests test and why

```
Give an example
```

## Deployment

Add additional notes about how to deploy this on a live system

## Built With

* [Dropwizard](http://www.dropwizard.io/1.0.2/docs/) - The web framework used
* [Maven](https://maven.apache.org/) - Dependency Management
* [ROME](https://rometools.github.io/rome/) - Used to generate RSS Feeds

## Authors

* **Cristina Villarroel** - *Lead Developer* - [cristyevr94](https://github.com/cristyevr94)
* **Antonio Valdes** - *Developer*

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

## Acknowledgments

* Thanks to Dr. Francisco Ortega for all his support.
